{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "1_G3XrmnS_p6b0q6HVXNW8ZHurmSxUMSH",
      "authorship_tag": "ABX9TyOM5f0ShNKC2CASTajVuH1/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FerreiraBX95/Master-Thesis---Bruno-Xavier-Ferreira/blob/Development-of-models-for-measurement-of-pH-in-atmospheric-and-pressurized-systems-using-artificial-intelligent-strategies/Code_for_training_the_classification_DT_models_Input_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECaZA7FPMvOt"
      },
      "source": [
        "*** Code for training the classification DT models - Input 2***"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH3T6rNaCOW8"
      },
      "source": [
        "Informações da GPU a ser utilizada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uztC3nbbCNSI"
      },
      "source": [
        "# Para usar a GPU eh preciso antes \"Alterar o tipo de ambiene de Execução\" para GPU\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print('Informacao da GPU: ')\n",
        "  print(gpu_info)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r97mcGr7B0pN"
      },
      "source": [
        "%pip install scikit-plot -q\n",
        "%pip install scikit-learn -q\n",
        "%pip install keras-metrics -q\n",
        "!pip install keras --upgrade\n",
        "!pip install tensorflow --upgrade\n",
        "!pip install sklearn --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlyASpTmCb9a"
      },
      "source": [
        "Bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJ_LonTCCd1q"
      },
      "source": [
        "# Bibliotecas\n",
        "\n",
        "import os\n",
        "import random\n",
        "\n",
        "import cv2\n",
        "from matplotlib import image\n",
        "from matplotlib import pyplot\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from tensorflow.keras import metrics\n",
        "\n",
        "from sklearn.metrics import roc_auc_score \n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.metrics import fbeta_score \n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score \n",
        "\n",
        "from skimage.transform import resize\n",
        "from scikitplot.metrics import plot_roc\n",
        "from scikitplot.metrics import plot_confusion_matrix\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkmMwfi8Cpo1"
      },
      "source": [
        "Carregamento e pre-processamento dos dados"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZ0N7fc-CvUh"
      },
      "source": [
        "## Teste para leitura de imagens do drive\n",
        "address = '/content/drive/MyDrive/Mestrado_Bruno Xavier/Dissertacao de Mestrado - Cod/Banco_de_Imagens_Curva_de_calib_PYTHON_med_pH_Alline_ajust'\n",
        "\n",
        "CATEGORIES = [\"pH_2\",\"pH_3\",\"pH_4\",\"pH_5\",\"pH_6\",\"pH_7\",\"pH_8\",\"pH_9\",\"pH_10\"]\n",
        "tam = 313\n",
        "#x_db = np.zeros((tam,800,1280,3),np.int16)\n",
        "x_db = np.zeros((tam,490,510,3),np.int16)\n",
        "y_db = np.zeros((tam,1),np.int16)\n",
        "\n",
        "ind = 0\n",
        "for category in CATEGORIES:  # do dogs and cats\n",
        "    path = os.path.join(address,category)  # create path to dogs and cats\n",
        "    for img in os.listdir(path):  # iterate over each image per dogs and cats\n",
        "        img_cap = image.imread(os.path.join(path,img))  # convert to array\n",
        "        img_cap = img_cap[190:680,350:860,:]\n",
        "        if category == 'pH_2':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 0\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_3':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 1\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_4':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 2\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_5':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 3\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_6':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 4\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_7':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 5\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_8':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 6\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_9':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 7\n",
        "          ind = ind + 1\n",
        "        if category == 'pH_10':\n",
        "          x_db[ind,:,:,:] = img_cap\n",
        "          y_db[ind] = 8\n",
        "          ind = ind + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKsl-xHyC5Ol"
      },
      "source": [
        "print('Tam vetor x: ',len(x_db))\n",
        "print('Tam vetor y: ',len(y_db))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TH6XRxCDPQU"
      },
      "source": [
        "Contagem de itens por classe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixr5pkbLDThi"
      },
      "source": [
        "print(\"counts of label '0' (pH=2): {} \\n\".format(sum(y_db == 0)))\n",
        "print(\"counts of label '1' (pH=3): {}\".format(sum(y_db == 1))) \n",
        "print(\"counts of label '2' (pH=4): {}\".format(sum(y_db == 2))) \n",
        "print(\"counts of label '3' (pH=5): {}\".format(sum(y_db == 3))) \n",
        "print(\"counts of label '4' (pH=6): {}\".format(sum(y_db == 4))) \n",
        "print(\"counts of label '5' (pH=7): {}\".format(sum(y_db == 5))) \n",
        "print(\"counts of label '6' (pH=8): {}\".format(sum(y_db == 6))) \n",
        "print(\"counts of label '7' (pH=9): {}\".format(sum(y_db == 7))) \n",
        "print(\"counts of label '8' (pH=10): {}\".format(sum(y_db == 8)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VtOpmyRDWm2"
      },
      "source": [
        "Criação-treinamento-teste do modelo do Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbRPTPASfsNk"
      },
      "source": [
        "#from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ2cADZcODGr"
      },
      "source": [
        "from builtins import range\n",
        "from builtins import object\n",
        "\n",
        "num_training = x_db.shape[0]\n",
        "mask = list(range(num_training))\n",
        "x_db = x_db[mask]\n",
        "y_db = y_db[mask]\n",
        "print(\"x_db: \"+str(x_db.shape))\n",
        "print(\"y_db: \"+str(y_db.shape))\n",
        "\n",
        "x_db = np.reshape(x_db, (x_db.shape[0], -1))\n",
        "print(\"x_db: \"+str(x_db.shape))\n",
        "print(\"y_db: \"+str(y_db.shape))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZObWqGqC-Hw"
      },
      "source": [
        "# Pode ser preciso rodar duas vezez\n",
        "x_train, x_test, y_train, y_test = train_test_split(x_db, y_db, test_size=0.3,random_state=1)\n",
        "x_test, x_val, y_test, y_val = train_test_split(x_test, y_test, test_size=0.5,random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnXVmzaSDHsV"
      },
      "source": [
        "print('Tam vetor y_train: ',len(y_train))\n",
        "print('Tam vetor y_train: ',len(y_test))\n",
        "print('Tam vetor y_val: ',len(y_val))\n",
        "print('Tam vetor y: ',len(y_db))\n",
        "print('Tam vetor y_som: ',len(y_train)+len(y_test)+len(y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyEa1BuOMN46"
      },
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import openpyxl\n",
        "from openpyxl import Workbook, load_workbook"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXFxwmMcy1hP"
      },
      "source": [
        "# Hyperparameters\n",
        "crit = ['gini', 'entropy']\n",
        "max_depth = [5, 7, 9, 11, None]\n",
        "max_leaf_nodes = [10, 20, None]\n",
        "min_samples_leaf = [1, 5, 7, 10]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwcBSBZ5MnRE"
      },
      "source": [
        "def train(model, filename, ind):\n",
        "  dados_perform = []\n",
        "\n",
        "  ini = time.time()\n",
        "  classifier.fit(x_train, y_train)\n",
        "  tempo_train = time.time()-ini\n",
        "\n",
        "  folderpath = '/content/drive/MyDrive/Mestrado_Bruno Xavier/Dissertacao de Mestrado - Cod/Cod outros algoritmos Python/Dec_tree_models-db_pH_Alline/'\n",
        "  fileaddress=folderpath+filename+'.pkl'\n",
        "  with open(fileaddress, 'wb') as file:\n",
        "    pickle.dump(classifier, file)\n",
        "  \n",
        "  dados_perform.append(filename)\n",
        "  dados_perform.append(tempo_train)\n",
        "\n",
        "  # Dados do grupo de treino\n",
        "  ini = time.time()\n",
        "  y_pred_train = classifier.predict(x_train)\n",
        "  #print('Tempo de Predicao-train: {}'.format(time.time()-ini))\n",
        "  prec = precision_score(y_train, y_pred_train, average='macro')\n",
        "  recall = recall_score(y_train, y_pred_train, average='macro')\n",
        "  acc = accuracy_score(y_train, y_pred_train)\n",
        "  f1 = f1_score(y_train, y_pred_train, average='macro')\n",
        "  #print('MSE: {} \\nRMSE: {}\\nPrecision: {}\\nRecall: {}\\nAccuracy: {} \\nf1-score:{}'.format(mse, rmse, prec, recall, acc, f1))\n",
        "  dados_perform.extend([prec, recall, acc, f1])\n",
        "\n",
        "  # Dados do grupo de validação\n",
        "  ini = time.time()\n",
        "  y_pred_val = classifier.predict(x_val)\n",
        "  #print('Tempo de Predicao-val: {}'.format(time.time()-ini))\n",
        "  prec = precision_score(y_val, y_pred_val, average='macro')\n",
        "  recall = recall_score(y_val, y_pred_val, average='macro')\n",
        "  acc = accuracy_score(y_val, y_pred_val)\n",
        "  f1 = f1_score(y_val, y_pred_val, average='macro')\n",
        "  #print('MSE: {} \\nRMSE: {}\\nPrecision: {}\\nRecall: {}\\nAccuracy: {} \\nf1-score:{}'.format(mse, rmse, prec, recall, acc, f1))\n",
        "  dados_perform.extend([prec, recall, acc, f1])\n",
        "\n",
        "  # Dados do grupo de teste\n",
        "  ini = time.time()\n",
        "  y_pred_test = classifier.predict(x_test)\n",
        "  #print('Tempo de Predicao-test: {}'.format(time.time()-ini))\n",
        "  prec = precision_score(y_test, y_pred_test, average='macro')\n",
        "  recall = recall_score(y_test, y_pred_test, average='macro')\n",
        "  acc = accuracy_score(y_test, y_pred_test)\n",
        "  f1 = f1_score(y_test, y_pred_test, average='macro')\n",
        "  #print('MSE: {} \\nRMSE: {}\\nPrecision: {}\\nRecall: {}\\nAccuracy: {} \\nf1-score:{}'.format(mse, rmse, prec, recall, acc, f1))\n",
        "  dados_perform.extend([prec, recall, acc, f1])\n",
        "\n",
        "  # Dados todas as imagens\n",
        "  ini = time.time()\n",
        "  y_pred_db = classifier.predict(x_db)\n",
        "  #print('Tempo de Predicao-geral: {}'.format(time.time()-ini))\n",
        "  prec = precision_score(y_db, y_pred_db, average='macro')\n",
        "  recall = recall_score(y_db, y_pred_db, average='macro')\n",
        "  acc = accuracy_score(y_db, y_pred_db)\n",
        "  f1 = f1_score(y_db, y_pred_db, average='macro')\n",
        "  #print('MSE: {} \\nRMSE: {}\\nPrecision: {}\\nRecall: {}\\nAccuracy: {} \\nf1-score:{}'.format(mse, rmse, prec, recall, acc, f1))\n",
        "  dados_perform.extend([prec, recall, acc, f1])\n",
        "\n",
        "  excel_address = '/content/drive/MyDrive/Mestrado_Bruno Xavier/Dissertacao de Mestrado - Cod/Cod outros algoritmos Python/Resultados_DecTree_models-db_pH_Alline.xlsx'\n",
        "\n",
        "  wb = load_workbook(excel_address)\n",
        "  ws = wb['Plan1']                     # Acesse Sheet 1\n",
        "  ws = wb.active                        # Use a aba ativa quando o arquivo foi carregado\n",
        "\n",
        "  ws['A'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['B'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['C'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['D'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['E'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['F'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['G'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['H'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['I'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['J'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['K'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['L'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['M'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['N'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['O'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['P'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['Q'+str(ind+2)]= dados_perform.pop(0)\n",
        "  ws['R'+str(ind+2)]= dados_perform.pop(0)\n",
        "\n",
        "  wb.save(excel_address)                # Salvar as modificacoes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lc90abXwzhnP"
      },
      "source": [
        "ini_geral = time.time()\n",
        "ind = 1\n",
        "for hypar1 in crit:\n",
        "  for hypar2 in max_depth:\n",
        "    for hypar3 in min_samples_leaf:\n",
        "      for hypar4 in max_leaf_nodes:\n",
        "        ini_part = time.time()\n",
        "        classifier = DecisionTreeClassifier(criterion= hypar1, max_depth= hypar2, min_samples_leaf= hypar3, max_leaf_nodes=hypar4)\n",
        "        filename = 'DecTree_model_'+str(ind)+'_hyperparm_crit-'+hypar1+'_max_depth-'+str(hypar2)+'_min_samples_leaf-'+str(hypar3)+'_max_leaf_nodes-'+str(hypar4)\n",
        "        train(classifier, filename, ind)\n",
        "        print('Teste: {} - tempo part={}'.format(ind, time.time()-ini_part))\n",
        "        ind = ind + 1\n",
        "\n",
        "print('Tempo total={}'.format(time.time()-ini_geral))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}